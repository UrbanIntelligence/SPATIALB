# SPATIALB 
## Spatial-Temporal Intelligence Evaluation Benchmark 
<img src="/logo.jpg" width="20%" >

We plan to develop a <b>SPA</b>tial-<u><b>T</b></u>emporal <u><b>I</b></u>ntelligence Ev<u><b>al</b></u>uation <u><b>B</b></u>enchmark (SPATIALB), that provides an evaluation framework with data, tasks, and metrics, to measure progress, catalyze innovation, and unite researchers around shared objectives in spatial-temporal AI, and fuel rapid advancement in this field. Our envisioned SPATIALB benchmark includes five major components: (1) tasks/competitions, (2) data, (3) evaluation metrics, (4) pre-training models, and (5) fine-tuning models. 

Our preliminary results were published in ICDM 2023, entitled "Self-supervised Pre-training for Robust and Generic Spatial-Temporal Representations", authored by Mingzhi Hu, Zhuoyun Zhong, Xin Zhang, Yanhua Li, Yiqun Xie, Xiaowei Jia, Xun Zhou, and Jun Luo. [pdf](https://users.wpi.edu/~yli15/res.html)
